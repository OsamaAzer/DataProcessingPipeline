{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "def load_data_from_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def load_data_from_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Region': ['East', 'West', 'East', 'West', 'East', None],\n",
    "    'Sales': [1000, 2000, np.nan, 3000, 1500, 1200],\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023/01/03', '2023-01-04', '2023-01-05', '2023-01-06']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Functional\n",
    "def functional_pipeline(dataframe, fill_defaults={'Region': 'Unknown', 'Sales': 0}, growth_factor=1.1, save_to_file=False):\n",
    "    \n",
    "    def fill_missing(df):\n",
    "        new_df = []\n",
    "        for _, row in df.iterrows():\n",
    "            new_row = {\n",
    "                'Region': row['Region'] if pd.notnull(row['Region']) else fill_defaults['Region'],\n",
    "                'Sales': row['Sales'] if pd.notnull(row['Sales']) else fill_defaults['Sales'],\n",
    "                'Date': row['Date']\n",
    "            }\n",
    "            new_df.append(new_row)\n",
    "        return pd.DataFrame(new_df)\n",
    "\n",
    "    \n",
    "    def standardize_dates(df):\n",
    "        new_df = []\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                row['Date'] = pd.to_datetime(row['Date']).strftime('%Y-%m-%d')\n",
    "            except Exception:\n",
    "                row['Date'] = None\n",
    "            new_df.append(row)\n",
    "        return pd.DataFrame(new_df)\n",
    "\n",
    "   \n",
    "    def filter_sales(df):\n",
    "        return pd.DataFrame([row for _, row in df.iterrows() if row['Sales'] > 1000])\n",
    "\n",
    "    \n",
    "    def add_sales_growth(df):\n",
    "        new_df = []\n",
    "        for _, row in df.iterrows():\n",
    "            row['Sales Growth'] = row['Sales'] * growth_factor\n",
    "            new_df.append(row)\n",
    "        return pd.DataFrame(new_df)\n",
    "\n",
    "    \n",
    "    def aggregate_data(df):\n",
    "        regions = {}\n",
    "        for _, row in df.iterrows():\n",
    "            region = row['Region']\n",
    "            if region not in regions:\n",
    "                regions[region] = {'Sales': [], 'count': 0}\n",
    "            regions[region]['Sales'].append(row['Sales'])\n",
    "            regions[region]['count'] += 1\n",
    "        results = []\n",
    "        for region, stats in regions.items():\n",
    "            total_sales = sum(stats['Sales'])\n",
    "            average_sales = total_sales / stats['count']\n",
    "            results.append({'Region': region, 'Total Sales': total_sales, 'Average Sales': average_sales})\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    # Compose all functions\n",
    "    transformed_df = fill_missing(dataframe)\n",
    "    transformed_df = standardize_dates(transformed_df)\n",
    "    transformed_df = filter_sales(transformed_df)\n",
    "    transformed_df = add_sales_growth(transformed_df)\n",
    "    aggregated_df = aggregate_data(transformed_df)\n",
    "\n",
    "    if save_to_file:\n",
    "        save_data_to_csv(transformed_df, 'functional_transformed.csv')\n",
    "        save_data_to_csv(aggregated_df, 'functional_aggregated.csv')\n",
    "\n",
    "    return transformed_df, aggregated_df\n",
    "\n",
    "# Imperatuve\n",
    "def imperative_pipeline(dataframe, fill_defaults={'Region': 'Unknown', 'Sales': 0}, growth_factor=1.1, save_to_file=False):\n",
    "    \n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['Region'] = dataframe['Region'].fillna(fill_defaults['Region'])\n",
    "    dataframe['Sales'] = dataframe['Sales'].fillna(fill_defaults['Sales'])\n",
    "\n",
    "    \n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'], errors='coerce')\n",
    "\n",
    "    \n",
    "    filtered_df = dataframe[dataframe['Sales'] > 1000].copy()\n",
    "\n",
    "    \n",
    "    filtered_df['Sales Growth'] = filtered_df['Sales'] * growth_factor\n",
    "\n",
    "    \n",
    "    aggregated_df = (\n",
    "        filtered_df.groupby('Region')['Sales']\n",
    "        .agg(['sum', 'mean'])\n",
    "        .reset_index()\n",
    "        .rename(columns={'sum': 'Total Sales', 'mean': 'Average Sales'})\n",
    "    )\n",
    "\n",
    "    if save_to_file:\n",
    "        save_data_to_csv(filtered_df, 'imperative_transformed.csv')\n",
    "        save_data_to_csv(aggregated_df, 'imperative_aggregated.csv')\n",
    "\n",
    "    return filtered_df, aggregated_df\n",
    "\n",
    "\n",
    "def plot_data(aggregated_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Bar chart for Total Sales\n",
    "    plt.bar(aggregated_df['Region'], aggregated_df['Total Sales'], color='skyblue')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('Total Sales')\n",
    "    plt.title('Total Sales by Region')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_data_to_csv(dataframe, filename):\n",
    "    dataframe.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "print(\"Functional Programming Paradigm:\")\n",
    "transformed_df_func, aggregated_df_func = functional_pipeline(df, save_to_file=True)\n",
    "print(aggregated_df_func)\n",
    "\n",
    "print(\"\\nImperative Programming Paradigm:\")\n",
    "transformed_df_imp, aggregated_df_imp = imperative_pipeline(df, save_to_file=True)\n",
    "print(aggregated_df_imp)\n",
    "\n",
    "# View charts\n",
    "print(\"\\nPlotting Functional Results:\")\n",
    "plot_data(aggregated_df_func)\n",
    "\n",
    "print(\"\\nPlotting Imperative Results:\")\n",
    "plot_data(aggregated_df_imp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
